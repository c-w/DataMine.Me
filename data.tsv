Date	Type	URL	Title	Topic	Summary
2015-12-24	Article	https://medium.com/@aboodman/in-march-2011-i-drafted-an-article-explaining-how-the-team-responsible-for-google-chrome-ships-c479ba623a1b	How Chromium Works	Software Engineering	Great overview of the software development process of the Chromium project, one of the biggest and most successful open source projects out there. The article claims that the main ingredient to their rapid ship cycle is that every developer always works off of head (to avoid costly integrations) which is enabled by high test coverage (to avoid breaking things) and feature flags (to hide partial features until they ship). They also talk about relentless refactoring but fail to mention how large-scale refactors fit in with constantly working off of head: how does one check in a partially completed refactor?
2015-12-06	Book	http://www.amazon.co.uk/dp/B00B0SA1LY/	Keeping Up with the Quants: Your Guide to Understanding and Using Analytics	Management	Lots of fluff and not much substance. The majority of the book is filled with examples of how real-world companies solved some problems with data and how they went about solving the problem. The main interesting point in the book is the framework that the authors introduce to discuss data problems. The framework is useful in order to keep in mind that problem recognition, definition and communication are as important as solving the analytical issues at hand.
2015-10-30	Book	http://www.amazon.co.uk/dp/B005OYHF0A/	Working Effectively with Legacy Code	Software Engineering	One of the best hands-on books on writing good code in recent memory. Lots of practical advice on how to write testable (i.e. maintainable) code and how to safely make bad code more testable. Succinctly written and a good reference on the how-why-and-when of a variety of refactors.
2015-10-15	Book	http://www.amazon.co.uk/dp/B004R9QACC/	The Psychology of Computer Programming	Software Engineering	An interesting classic: thirty years old and yet it contains a lot of wisdom that is only slowly and gradually being accepted and applied (and where it is applied, usually to universal success) -- however, the book is also quite dated in many ways, relatively low on information density and therefore ultimately not an enjoyable-or-commendable read to anyone but the 'Agile historian'; more modern texts simply offer more to the practitioner.
2015-07-26	Paper	http://vita.had.co.nz/papers/tidy-data.pdf	Tidy Data	Data Science	The paper proposes a standard way to approach denormalizing data that makes it easier to visualize, analyze and find outliers: avoid encoding information in column headers, avoid multi-variate data-types in columns, avoid data-types that require both column and row values to encode information, avoid multiple data-types in the same table, avoid spreading a logical row over multiple tables, etc.
2015-06-25	Paper	https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf	A Few Useful Things to Know about Machine Learning	Machine Learning	Very high-level, easy to read, non-technical introduction to some of the main problems and gotchas in machine learning, e.g. evaluation, feature engineering, representation, etc. Probably a good text to give to family and friends who would like to know a bit more about the field. Anyone already involved in the field should already be familiar with everything mentioned in the paper and can therefore pass on it.
2015-06-25	Article	http://www.knime.org/blog/seven-techniques-for-data-dimensionality-reduction	Seven Techniques for Data Dimensionality Reduction	Machine Learning	Missing value ratio: remove features with high number of missing values. Low variance filter: remove features with low variance (only applies to numeric features). High correlation filter: remove correlated features using Person's Product Moment Coefficient or Chi-Squared test - remember to scale features first (doesn't work for numeric/categorical pairs of features). Trees: build a random forest on the data and see how often each feature is used in the ensemble - frequently used features are good features due to having a high information gain. Principal components: PCA destroys feature interpretability (only applies to numeric features). Backward elimination: remove one feature at a time and re-train the classifier and kill the feature with the lowest increase in error (very slow). Forward construction: start with one feature and add features to the classifier until the error decrease is small (very slow). They compare all approaches on the KDD-2009 data-set and find that Trees perform best in terms of dimensionality-reduction-to-AUC ratio but that simple methods like Missing value/high-correlation filters are not far behind.
2015-06-22	Article	https://www.chrisstucchio.com/blog/2013/hadoop_hatred.html	Don't use Hadoop - your data isn't that big	Data Science	Short rant on the over-use of map-reduce for small data-set sizes and how that puts constraints on the types of expressible computations. Alternatives: add more memory to your server and process the data in memory or stream it. If the data is really too big for memory, check if a database on an SSD will give decent performance. Map-reduce should be reserved for terabyte-scale data. Hard to disagree with the pragmatism.
2015-06-22	Article	https://blog.lateral.io/2015/06/the-unknown-perils-of-mining-wikipedia/	The Unknown Perils of Mining Wikipedia	Data Science	Cute cautionary tale about the importance of data-cleanup. It turns out that most of Wikipedia was written by natural language generation algorithms running on databases of facts, e.g. about small towns or rivers. A failure to remove these articles from a crawl of Wikipedia will lead to terrible training data. Work-around: only train on the head articles, i.e. the articles that get lots of human eyeballs.
2015-06-21	Paper	http://research.microsoft.com/pubs/163083/hotcbp12%20final.pdf	Nobody ever got fired for using Hadoop on a cluster	Data Science	The paper makes the argument that for most data-set sizes common in industry, using a cluster of map-reduce machines is inefficient compared to using fewer but bigger servers given recent reductions in the cost of memory. Other advantages of bigger servers over clusters are better algorithms (no distributed approximations required) and a simpler programming model. The down-side of having to load more data on a single machine can be mitigated to some extent by investing into better ethernet connections and faster disks.
2015-06-06	Book	http://www.amazon.co.uk/dp/B00HEL13HW/	Lean Software Development: An Agile Toolkit	Software Engineering	The first few chapters of this book were quite interesting, likening the origins of the lean software movement to its roots in lean manufacturing: which practices made sense to port over, which were inappropriate, what ideas should we still adopt, etc. I especially liked the rather critical view taken on the dogmatic appropriation of Agile techniques - a breath of fresh air. The later parts of the book strayed into a lot heavier management territory and thus were less useful from an software engineer's point of view: team building, motivation, contracts, etc. Summary: the first half well worth reading, the latter half only for aspiring managers.
2015-05-21	Article	https://mpld3.github.io/index.html	MPLD3	Libraries	Wrapper around Matplotlib that renders graphs to interactive Javascript. Very cool.
2015-05-21	Article	https://github.com/trevorstephens/gplearn	gplearn	Libraries	SciKit-Learn style wrapper for some genetic algorithm libraries... more fancy stuff made easier.
2015-05-21	Article	https://github.com/aigamedev/scikit-neuralnetwork	scikit-neuralnetwork	Libraries	SciKit-Learn style wrapper around a bunch of standard neural network libraries... reduces the barrier to entry.
2015-05-21	Article	http://karpathy.github.io/2015/05/21/rnn-effectiveness/	The Unreasonable Effectiveness of Recurrent Neural Networks	Machine Learning	Very fun blog-post that walks through using RNNs to generate natural language and structured texts from character level input. Gives a lightweight background on the theory behind character-level networks and talks about some practical considerations. Unfortunately doesn't compare the RNN output to simpler models like Markov Chains or N-Gram language models to ground their performance.
2015-04-27	Paper	http://ccr.sigcomm.org/online/files/p83-keshavA.pdf	How to Read a Paper	Meta	Classic short text presenting a three-step approach to reading academic papers efficiently. The first pass should be a very short weed-out pass: what are the conclusions, what is the impact, is it likely to be correct, is it relevant to your research. The second pass is there to find flaws in the argument (requires getting a good understanding of the main argument). If the paper is not 100% relevant to your research, stop now. Otherwise, the third pass is the deconstruction piece: what are the strong/weak points of the paper, reach the same conclusions as the paper given the same assumptions, what are good avenues for future work.
2015-04-26	Paper	http://olivier.chapelle.cc/pub/tnn99.pdf	SVMs for Histogram-Based Image Classification	Computer Vision	The paper makes a case for using color histograms for image representation: invariant under scale, rotation, translation, easy to compute. They use linear SVMs and SVMs with fancy kernels on top of the color histogram representation. They find that exponentiating the histogram bins (x_i := x_i^a for 0 <= a <= 1) makes linear SVMs perform almost as well as fancy SVMs.
2015-04-26	Article	http://techblog.netflix.com/2015/04/learning-personalized-homepage.html	Learning a Personalized Homepage	Machine Learning	Netflix's uses a three-step approach to page generation: first predict how a user would score a particular title, from this generate rows of content and then select which rows to show and in which order. All fairly standard stuff but for one interesting point: in order to avoid having monotonous content on the page, they score each row individually and combine it with a score relative to its neighbours to increase diversity.
2015-04-26	Article	http://tech.grammarly.com/blog/posts/How-to-Split-Sentences.html	How to Split Sentences	Natural Language Processing	Comparison of some off-the-shelf sentence splitters. Stanford CoreNLP (finite-state-machine word-tokenization first, then sentence grouping) and OpenNLP (word-boundary detection as a classification problem) have very low error rates. Regular expression based approaches work less well. The analysis should be taken with a grain of salt (they only used a single source of documents, reporting point-estimates instead of cross-validation results, etc.) but is likely a good starting point when prioritizing what sort of sentence splitter to try first on one's own dataset.
2015-04-16	Article	https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century	Data Scientist: The Sexiest Job of the 21st Century	Data Science	Lots of hype around this article so it had to be read eventually. Turns out that the piece is a surprisingly good birds-view description of the who-what-why-and-where of data science. Great article to send to non-technical folk who are curious about the field.
2015-04-16	Article	http://fotiad.is/blog/sentiment-analysis-comparison	A comparison of open source tools for sentiment analysis	Natural Language Processing	The author compares a number of different approaches to sentiment analysis. The first approach is based on bag-of-words plus Naive Bayes. The second approach is based on lexicons: words are associated with a positive or negative score and word-scores are aggregated over the entire text. (Immediate concern: the approach requires word sense disambiguation - this is a really hard problem! The author uses the standard naive WordNet-overlap approach.) The third approach uses the deep-net classifier that is part of Stanford CoreNLP. (Immediate concern: the classifier is trained on data from an entirely different domain.) The Naive Bayes approach beats out the other two, achieving about 90% accuracy. The result is somewhat unsurprising as the lexicon approach is constrained by the guaranteed poor performance of the author's word-sense disambiguation technique and the CoreNLP deep-net is trained on out-of-domain data. The text shows - once again - the power of simple methods like bag-of-words, but the results shouldn't be taken too seriously. A more interesting comparison would have re-trained the deep-net to answer the question how much a learned representation of the text improves classification performance.
2015-03-29	Video	https://www.youtube.com/watch?v=5Dnw46eC-0o	Statistics Without the Agonizing Pain	Statistics	Interesting take on using experiments and computational methods like randomized permutations or boostrapping to understand statistical phenomena instead of relying on difficult to understand formulae.
2015-03-22	Paper	http://www.cs.ubc.ca/research/flann/uploads/FLANN/flann_visapp09.pdf	Fast Approximate Nearest Neighbors With Automatic Algorithm Configuration	Machine Learning	They released an algorithm that selects the fastest nearest-neighbor search algorithm for some data-set. For most data-sets (even in high dimensions), it turns out that searching trees of hierarchical k-means clusters or randomized kd-trees work well. It is not surprising but nevertheless interesting that decomposing a hard problem in high dimensions into many smaller problems in lower dimensions works well.
2015-03-22	Paper	http://vision.ece.ucsb.edu/~zuliani/Research/RANSAC/docs/RANSAC4Dummies.pdf	RANSAC for dummies	Statistics	Regression algorithm that can was designed to deal with lots of outliers; the algorithm can handle more than half of the data-set being outliers. First, we create random minimal sample sets from the data. The size of these sets should be just big enough to fit our regression e.g., two elements for a two-dimensional feature space. We then fit a regression to the minimal sample sets and check how many points in the full data-set are consistent with this regression up to some delta of error. Iterate a fixed number of times or until the consensus set is large enough. Problems: how do we determine the error threshold and minimal acceptable consensus set size?
2015-03-22	Paper	http://arxiv.org/pdf/1502.01710v1.pdf	Text Understanding from Scratch	Natural Language Processing	They train a convolutional neural network on raw text (input features are non-overlapping windows of characters). They create additional noisy training data by replacing words in their training sentences with synonyms taken out of a dictionary which helps in making the network more invariant under non-semantic changes (like adding noise in speech recognition or scaling/rotating input images in computer vision). They apply the model to a bunch of different task such as predicting the star-rating of an Amazon review based on sentiment, predicting the ontological category of a DBpedia article and categorizing news into topics. They get pretty good results, out-performing their baseline implementations of bag-of-words and word2vect. The paper is pretty cool because it demonstrates once again that we probably don't need to engineer features when using neural networks and large enough training data!
2015-03-21	Article	http://www.win-vector.com/blog/2015/02/does-balancing-classes-improve-classifier-performance	Does Balancing Classes Improve Classifier Performance?	Machine Learning	The article experimentally explores how over-sampling a minority class affects classification performance of logistic regression, random forest and soft-margin support vector machine. Turns out that over-sampling is a really bad idea for logistic regression (logistic regression calibrates well to the distribution of the data so fudging the distribution will naturally affect performance), does not affect support vector machine (the training procedure is not strongly dependent on class distribution: performance depends on class distance from the margin - if both classes are far away from the margin, their distribution doesn't matter much) and improves performance of random forest. On the bright side: over-sampling will necessarily increase recall.
2015-03-21	Article	http://www.kdnuggets.com/2015/03/machine-learning-data-science-common-mistakes.html	7 common mistakes when doing Machine Learning	Machine learning	Don't always use the default loss function (e.g. Huber loss is good to not heavily penalize outliers and hinge loss is good to not penalize small mistakes). Add interaction terms to achieve non-linearity when using linear models, e.g. logistic regression. Always check for outliers! Always standardize features when using regularization. Coefficient sizes of linear models not always interpretable as feature importance, e.g. when attributes co-linear or not standardized.
2015-03-21	Article	http://technology.stitchfix.com/blog/2015/03/17/grammar-of-data-science	The Grammar of Data Science	Data Visualization	The article compares using R over Python for exploratory data analysis and gives some compelling arguments in favour of R. Most interestingly, R is able to plot categorical versus numeric data out of the box!
2015-03-21	Article	http://engineering.intenthq.com/2015/02/automatic-topic-modelling-with-lda	Automatic topic-modelling with Latent Dirichlet Allocation	Natural Language Processing	Useful comparison of a bunch of different LDA libraries, e.g. MALLET is no longer being developed and we should probably all be using GenSim due to focus on performance and ease-of-use.
2015-03-21	Article	http://blog.echen.me/2014/10/07/moving-beyond-ctr-better-recommendations-through-human-evaluation	Moving Beyond CTR: Better Recommendations Through Human Evaluation	Machine Learning	Interesting essay on trying to move away from click-through-rate as the main way of evaluating the performance of recommender systems. The article argues that click-through-rate is expensive to experiment with (requires full-scale A/B test) and is a poor proxy for quality of recommendations (clicks do not necessarily imply satisfaction with the content). The article argues that we should be using human evaluation to validate new recommenders (which also allows us to get feedback while building a new algorithm, not only once we're done and productionized). Obviously, there are some issues with the approach recommended by the article: it is hard to scale human evaluation and there is no jeopardy for the participant, i.e. although they might say that they are satisfied with some recommendation, that does not necessarily translate into purchase intent given that agreeing with some recommendation does not cost the participant anything. Using human evaluation during the prototyping phase of recommender development, on the other hand, does sound appealing.
2015-03-04	Article	http://hunch.net/?p=22	Clever Methods of Overfitting	Machine Learning	Good enumeration of different ways in which we can over-fit models, ranging from the classic 'too complex model with too little data' over to 'too finely tuned meta-parameters' to more subtle points like choosing the metric that makes our algorithm look good or choosing metrics that are inherently prone to over-fitting (like entropy, mutual information or leave-one-out cross validation).
2015-02-21	Book	http://www.amazon.co.uk/dp/B008HMN5BE/	Data Jujitsu: The Art of Turning Data into Product	Data Science	Interesting diatribe porting some of the lean-agile principles to data-based products. E.g. validate product idea before investing in fancy algorithms and systems (c.f. Amazon building simple collaborative filtering to validate need for recommender systems, c.f. Using humans as initial version of a machine learning system). E.g. trade-off precall for precision when machine learning system has accountability i.e. explains what it's doing: false positives are more costly in terms of user trust. E.g. ground user's expectations: under-promise and over-deliver. E.g. use humans in the loop (c.f. LinkedIn's recommend this recommended job to a friend acts both as a buffer to not disappoint users with bad recommendations and as a way to get good training data on which jobs are relevant). E.g. engage users with the product (c.f. Give access to user's data so that they can feel in charge and clean it up). E.g. try to collect highest quality data possible (c.f. Limit number of free-text fields, pre-populate fields, etc.).
2015-02-20	Book	http://www.amazon.co.uk/dp/B00TKGY0GU/	Effective Python: 59 Specific Ways to Write Better Python	Software Engineering	Much more language specific than 'Effective Java'. Most of the stuff in here would probably be of most use to advanced beginners and should be obvious to anyone with some experience (Pythonic Thinking, Functions, Classes and Inheritance, Built-in Modules, Collaboration, Production). Some of the contents I found useful (descriptors, metaclasses, concurrency),
2015-02-18	Paper	http://www.uni-weimar.de/medien/webis/publications/papers/lipka_2010.pdf	Comparison of Language Identification Approaches on Short, Query-Style Texts	Natural Language Processing	Very short paper looking at different ways to determine the language of short fragments of text. They find that using an n-gram based classifier approach they can achieve almost 100% accuracy, beating vector space models and language models. This means that we probably have some highly discriminative n-grams between languages and a lot of non informative n-grams (consistent with what we'd expect intuitively). I was able to reproduce their result that using an n-gram based classifiers solves this problem almost perfectly.
2015-02-18	Paper	http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/37195.pdf	Detecting Adversarial Advertisements in the Wild	Machine Learning	Interesting paper from Google on how much work goes into using relatively simple machine learning techniques (stochastic gradient descent) in an industry setting (learning at scale, high cost of mistakes, human-in-the-loop, changing data over time). The sections on monitoring and adapting their systems in production is especially interesting. When they re-train the production model, the new model must pass some precision/recall tests on held out data before it gets promoted to production. They also monitor the distribution of the input features and output decisions to assert that they stay reasonable similarly distributed/relevant over time.
2015-02-18	Paper	http://jmlr.csail.mit.edu/papers/volume15/delgado14a/delgado14a.pdf	Do we Need Hundreds of Classifiers to Solve Real World Classification Problems?	Machine Learning	The paper compares the performance of 179 implementations of assorted classifiers on 121 open data-sets without any data pre-processing or feature engineering. They find that random-forests and SVMs with non-linear kernels have the best performance on average in binary and multi-class settings.
2015-02-18	Article	https://hbr.org/2014/05/10-kinds-of-stories-to-tell-with-data/	10 Kinds of Stories to Tell with Data	Data Science	Taxonomy of different types of analytics stories along dimensions. Time: reporting (describing the past), surveying (explaining the present), predicting (modelling the future). Focus: what is going on, why is it going on, how to fix it. Methods: correlation story, causation story (requires experiment).
2015-02-18	Article	http://deloitte.wsj.com/cio/2015/02/10/why-data-storytelling-is-so-important-and-why-were-so-bad-at-it/	Why Data Storytelling is So Important, and Why We're So Bad at It	Data Science	Mostly fluff/obvious piece about why adding a story to data analysis is important (more easily understood by stakeholders, etc.), but with one interesting point. Given that there are supposedly only 7 types of literary narratives, using stories to communicate the results of data analytics might enable us to standardize the stories we tell with the analytics to a similar set of standard pieces. This will make it easier to communicate the high level picture of the analysis.
2015-02-13	Article	https://www.chrisstucchio.com/blog/2015/dont_use_bandits.html	Don't use Bandit Algorithms - they probably won't work for you	Statistics	Explanation of the underlying assumptions in some of the classic bandit algorithms and how frequent real-world experiment settings violate these (leading to worse performance than standard A/B tests). E.g. bandits assume no delay between impulse and response (real world conversion can take days). E.g. bandits assume uniform response rate (real world conversion and levers can be correlated).
2015-02-13	Article	http://www.kdnuggets.com/2015/02/10-things-statistics-big-data-analysis.html	10 things statistics taught us about big data analysis	Statistics	Some stats tricks relevant to machine learning. E.g. time-series data should be smoothed for better results. E.g. explicitly address confounding factors like inter-class variance over time.
2015-02-13	Article	http://www.firstclassanalytics.com/is-a-low-r-squared-statistic-a-bad-thing.html	Is A Low R-Squared Statistic A Bad Thing?	Statistics	The article argues that a low R^2 statistic for a regression model is not a bad thing for a model if the model attributes have good p-values -- low R^2 might simply mean that there are other attributes outside of our model that explain some of the variance in the data, not that the model we have is bad. We shouldn't indiscriminately add attributes to a model just to increase R^2 (as a matter of fact, the more attributes we add the higher R^2 is likely to be) but be judicious in choosing which attributes to add in adding more attributes (domain knowledge, p-values).
2015-02-08	Paper	http://www.kurims.kyoto-u.ac.jp/EMIS/journals/RCE/V35/v35n2a03.pdf	Comparison between SVM and Logistic Regression: Which One is Better to Discriminate?	Machine Learning	Theoretical and experimental comparison of Support Vector Machines versus Logistic Regression. When the data is multi-variate, drawn from a mixture of distributions or strongly correlated SVM is better. SVM can also achieve better results with fewer features. Logistic Regression is better for some underlying distributions in the data (Poisson, Exponential, Normal).
2015-02-08	Paper	http://onlinelibrary.wiley.com/doi/10.1002/uog.2791/pdf	Support vector machines versus logistic regression: improving prospective performance in clinical decision-making	Machine Learning	Fairly one-sided comparison of logistic regression and support vector machines. The paper claims that the latter is less likely to over-fit, better handles outliers and can better handle non-linearities in the data via kernels. The paper backs the claims up by comparing the performances of the two classifiers on data-sets with less than 100 examples.
2015-02-04	Article	http://svds.com/post/avoiding-common-mistake-time-series	Avoiding a common mistake with time series	Statistics	Cautionary tale about how trends in time series data can lead to strong correlations in unrelated data: if the trend is large compared to the actual data, the correlation between trends will overwhelm the non-correlation between the data. Work around: model the trend explicitly e.g. using linear regression and subtracting the fit or use differences between data points instead of raw data.
2015-02-04	Article	http://scikit-learn.org/stable/tutorial/machine_learning_map/	Choosing the right estimator	Machine Learning	Awesome task-to-algorithm decision tree made by the Scikit-learn team. Gives a nice overview of which machine learning algorithms are canonical for what sorts of problems and requirements.
2015-02-01	Article	https://jmetzen.github.io/2015-01-29/ml_advice.html	Advice for applying Machine Learning	Data Science	Some interesting guidelines on how to get started tackling a new dataset. E.g., when data-dimensionality is low, use a correlation plot as a cheap way to separate noisy features from informative features and to filter out correlated features. E.g., plot learning curve to visualize difference in training versus cross-validation error. If training error is much higher than cross-validation error, we are likely over-fitting (fix by using more training data, stronger regularization or L1 regularization to force feature sparsity). If training error is very high, we are likely under-fitting i.e., using the wrong model for the data (fix by adding more features or non-linear kernels). E.g., use progressive validation when there is too much data for cross-validation: train model in batches, evaluate the model on the next batch, add the batch to the training data, re-evaluate and check how well we adapted to the new data - when we no longer improve, might as well stop training.
2015-01-25	Paper	http://arxiv.org/pdf/1411.4555v1.pdf	Show and Tell: A Neural Image Caption Generator	Natural Language Processing	Google using deep neural nets to achieve infuriatingly good results in image description generation: 3x improvement in BLEU over the state of the art. What's the secret-sauce? They train a neural network on raw images and then feed that into a language generation neural network that predicts word N+1 in the description using the image representation generated by the image recognizer and words 1..N in the training descriptions (basically like decoding in machine translation).
2015-01-19	Paper	http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43146.pdf	Machine Learning: The High-Interest Credit Card of Technical Debt	Software Engineering	Lessons from real-world machine learning at Google. The paper mentions several anti-patterns to avoid and how to address them. E.g. entanglement/tight coupling/changing anything changes everything. It's easy to build v1 of a machine learning system, very complicated to make changes without changing the behavior of the entire model. Mitigation: metrics for all the dimensions, ensembling, better regularization. E.g. hidden feedback loops. Behavior of system affects future training data. Mitigation: ... un-solved problem. E.g. unstable data dependencies. Changes in input data sources can affect behavior of model. Mitigation: data versioning, but this is expensive in terms of engineering. E.g. underutilized features. Features with small improvement in model performance carry high cost and risk (see unstable data dependencies). Mitigation: regularly evaluate features and prune mercilessly. E.g. correction cascades. Models that use other models as features lead to coupling and make it more difficult to improve the models because of complex effects on the down-stream models. Mitigation: add the extra features of the down-stream model directly to the upstream-model. E.g. glue code. Interfacing with machine learning systems lead to glue code to adapt to the interface. Usually this means tight-coupling with particular versions. Mitigation: re-write the algorithms in the system language. E.g. monitoring. Difficult to know the correct behavior of a constantly adapting system. Mitigation: assert that observed and predicted priors are similar and threshold model confidence before taking action.
2015-01-18	Book	http://www.amazon.co.uk/dp/0321213351/	Refactoring to Patterns	Software Engineering	Not sure how useful this book is. On one hand, the text offers a good introduction to some of the more widely used patterns - much more approachable than the Gang-of-Four book. On the other hand, because the book focuses on the more readily applicable patterns, I found there to be little value or news in the text.
2015-01-18	Article	http://engineering.shapesecurity.com/2015/01/detecting-phantomjs-based-visitors.html	Detecting Phantom JS-based visitors	Software Engineering	Interesting post talking about how to detect headless browsers. Most of the tips are fairly specific to Phantom JS, however, the post nicely shows the mindset to have if one truly wants to get rid of headless traffic: know and exploit the quirks in the headless rendering engines or use delay-based approaches.
2014-12-07	Paper	http://storm.cis.fordham.edu/gweiss/papers/dmin07-weiss.pdf	Cost-Sensitive Learning vs. Sampling: Which is Best for Handling Unbalanced Classes with Unequal Error Costs?	Machine Learning	Two main approaches. 1. Use a cost sensitive algorithm i.e. encode a penalty for wrong classifications of a particular class in the objective function. 2. Use sampling to make the data-ratios more equal. Sampling is the way to go when there is no cost-sensitive version of the preferred learning algorithm or when we need to subsample the data anyway e.g. because we have too much of it. If we don't know the correct class weights, we should use area under ROC curve as objective function to find the correct sampling rate or class weights. For small data-sets, don't use under-sampling because we can't afford to reject training examples and cost-sensitive learning might be worse than over-sampling because the classifier doesn't have enough data-points to estimate the correct class weights. For large data-sets cost-sensitive learning is usually best.
2014-12-07	Paper	http://arxiv.org/pdf/1106.1813.pdf	SMOTE: Synthetic Minority Over-sampling Technique	Machine Learning	Better than over-sampling with replacement: create artificial examples by interpolating between k-nearest-neighbours. This leads to larger and less specific decision boundaries instead of over-sampling's more specific boundaries i.e. less chance of over-fitting. Extensions of the technique to non-numeric features exist.
2014-12-07	Article	http://blog.david-andrzejewski.com/machine-learning/practical-machine-learning-tricks-from-the-kdd-2011-best-industry-paper	Practical machine learning tricks from the KDD 2011 best industry paper	Machine Learning	Some useful machine learning in the wild tricks from Google: use ensemble methods, get a human into the loop on low-confidence data-points, use many features and let L1 regularization trim the space down, avoid having to classify entries by ranking them instead (easier), monitor performance of system in the wild (e.g. permanently re-compute model precision and recall).
2014-11-30	Book	http://www.amazon.co.uk/dp/0978739213/	Release It!: Design and Deploy Production-Ready Software	Software Engineering	This book was a real mixed bag. On one hand, a lot of the advice in the book seemed quite technology specific and will probably be out-of-date sooner rather than later. On the other hand, there was a lot of good stuff in here about how to build robust and failure-tolerant systems and architecture. Just being aware of the patterns and failure-modes that the book talks about made me think differently about my day-to-day work. This is one to be re-visited further down the road of the software developer journey.
2014-11-26	Article	http://www.theverge.com/2014/11/25/7276157/nanogenmo-robot-author-novel	The strange world of computer-generated novels	Natural Language Processing	Very cool NLG idea: spend November (NaNoWriMo) writing a program to generate a novel.
2014-11-25	Article	http://web.stanford.edu/~mwaskom/software/seaborn	Seaborn: statistical data visualization	Libraries	Wrapper around Matplotlib to make simple plot creation easier.
2014-11-25	Article	http://geoffboeing.com/2014/08/clustering-to-reduce-spatial-data-set-size	Clustering to Reduce Spatial Data Set Size	Machine Learning	Comparison of K-Means and DBSCAN clustering algorithms. Naturally the later wins because it is able to infer the number of clusters automatically and does not suffer from initialization problems.
2014-11-25	Article	http://fnl.es/a-review-of-sparse-sequence-taggers.html	A review of sparse sequence taggers	Libraries	Comparison of discriminative sequence tagging libraries based Conditional Random Fields (allows for any state in the sequence to be considered when making the tagging decision - prone to overfitting and slow) and MaxEnt Markov Models (only considers local context when making the tagging decision - fast and less likely to overfit but weaker features). Stanford Tagger, Mallet, CRF++ and SVM tool are too slow. OpenNLP only has MEMM, CRF Suite only has CRF. OpenNLP has no multi-core support. Wapiti is the best compromise between completeness, efficiency, documentation and accuracy.
2014-11-25	Article	http://blog.dominodatalab.com/using-data-science-to-get-a-good-deal-on-a-macbook	Using Data Science to get a Good Deal on a Macbook	Data Science	Some interesting pragmatic data pre-processing ideas. E.g.: using anomaly detection to remove the need for creating a labelled data set from a classification problem and using LDA to find regular expressions that will cheaply capture some aspects of clusters in the data.
2014-10-25	Book	http://www.amazon.co.uk/dp/0132350882/	Clean Code: A Handbook of Agile Software Craftsmanship	Software Engineering	Lots of good stuff in here about low level things that make code readable. The writing is quite entertaining. Most importantly, the book has lots of examples that make it easy to relate to the concepts that the author is trying to communicate. However, most (if not all) of the stuff in here is very basic and should already be known to anyone who has been writing software professionally for any amount of time. The book probably is a great resource for someone about to start an internship, but beyond that, I question its value.
2014-09-29	Article	http://blog.notdot.net/2010/07/Damn-Cool-Algorithms-Levenshtein-Automata	Damn Cool Algorithms: Levenshtein Automata	Natural Language Processing	There is a way to construct finite state automata that compute the edit distance between two strings. This means that we can compute edit distance in linear time (plus some one-time overhead to construct the automata).
2014-09-29	Article	http://blog.lostpropertyhq.com/postgres-full-text-search-is-good-enough/	Postgres full-text search is Good Enough!	Natural Language Processing	Lots of information retrieval functionality is built into Postgres by default: stemming, spell-checking, TF-IDF vectorization, query ranking, multi-language support, stop-wording, etc. This means we don't need to break out ElasticSearch for smaller scale full-text search.
2014-09-28	Book	http://www.amazon.co.uk/dp/B00DY5A8X2/	Peopleware: Productive Projects and Teams	Management	More of a hand-book for managers than a book about management. Lots of good, common sense advise about the day-to-day of building teams and running projects... But not very useful for non-manager types.
2014-08-29	Paper	http://arxiv.org/pdf/1101.2245v2.pdf	Invertible Bloom Lookup Tables	Computer Science	We can now enumerate the items in a Bloom filter!
2014-08-29	Paper	http://2013.berlinbuzzwords.de/sites/2013.berlinbuzzwords.de/files/slides/DanFilimon.pdf	Clustering data at scale	Machine Learning	Can reformulate K-Means as an (online) Map-Reduce problem.
2014-08-29	Book	http://www.amazon.co.uk/dp/B00B8V09HY/	Effective Java: Second Edition	Software Engineering	Not as mind-blowing as on its first read through, but still lots of good stuff. The first few chapters are a good general read and reminder of some of the important things when writing software. The later chapters (concurrency, serialization, etc.) make for good reference material.
2014-08-29	Article	http://firstround.com/article/What-I-Learned-As-Pandoras-First-Data-Scientist	What I Learned As Pandora's First Data Scientist	Data Science	It's important to have data scientists situated with the product teams - shorter feedback loops, closer to the product, can pitch in on the actual implementation, etc. For a data scientist manager it's important to pair up people with projects that interest them and make sure that there is enough mentoring or peer-learning going on.
2014-08-28	Article	http://jeremykun.com/2014/08/26/when-greedy-algorithms-are-perfect-the-matroid/	When Greedy Algorithms are Perfect: the Matroid	Computer Science	Matroid is a set of independence systems I over X such that any non-maximally independent set can be grown by adding an element from a bigger independent set. If a problem can be formulated as a Matroid then a greedy algorithm will always be optimal.
2014-08-28	Article	http://jakevdp.github.io/blog/2014/06/06/frequentism-and-bayesianism-2-when-results-differ/	Frequentism and Bayesianism II: When Results Differ	Statistics	Nuisance parameter: something that we have to estimate in order to measure the quantity we are interested in but that isn't directly relevant to the question at hand. Bayesian approach marginalizes them out, frequentist approach uses a single maximum likelihood estimate (which is probably going to be wrong - there are ways to fix this, but Bayesian formulation does it for free). Bayesian approach also better deals with outliers by accounting for them using a nuisance parameter and integrating their effect out.
2014-08-28	Article	http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/	Frequentism and Bayesianism: A Practical Introduction	Statistics	Frequentist approach treats probabilities as frequencies of events. Bayesian approach treats probabilities as notion of certainty of an event (prior knowledge + knowledge given observations). Advantage of Bayesian approach is that there is little need to change the model for more complicated problems (e.g. multi-dimensional or correlated data). Also doesn't make an implicit Gaussian assumption about the data or residuals. Drawback: overkill for simple problems.
2014-08-27	Article	https://plus.google.com/+YoshuaBengio/posts/GJY53aahqS8	Response to: Is Deep Learning the Final Frontier and the End of Signal Processing?	Machine Learning	Why does deep learning work? Distributed representation: every extra layer can represent an exponentially bigger family of functions because parameters can be reused: N parameters can be used to split 2^N input regions. Much more effective than non-distributed non-parametric learners like SVM or KNN.
2014-08-26	Paper	http://wwwold.cs.umd.edu/~elaine/docs/scambaiter.pdf	Scambaiter: Understanding Targeted Nigerian Scams on Craigslist	Data Science	Setting up a honey-pot to collect data about 491 scams. IP address and reply-to email address that differs from sent-from address are highly indicative features of scams. Images in emails that include images hosted on external servers are uncannily effective at gathering personal information via emails.
2014-08-26	Paper	http://research.microsoft.com/pubs/167719/WhyFromNigeria.pdf	Why do Nigerian Scammers Say They are from Nigeria?	Machine Learning	Using reasoning based on ROC curves to find analytic bounds of classifier performance.
2014-08-26	Paper	http://delivery.acm.org/10.1145/1730000/1722966/p4-su.pdf	A Survey of Collaborative Filtering Techniques	Machine Learning	Main challenges in recommenders. Data sparsity: use dimensionality reduction (LSI, PCA) or try to do local recommendations in some cluster e.g. by using a decision tree or explicit clustering or external information (like product taxonomy). Scalability: there exists an incremental version of SVD,  if possible only compare co-rated items. Synonymy: LSI fixed this automatically or domain specific thesaurus. Shilling attacks: item-based more robust, explicitly account for it during data normalization, work with similarity residuals instead of absolute values. Memory-based collaborative filtering algorithm: find similar users (e.g. Pearson correlation or cosine similarity) and then aggregate their likes into recommendations (e.g. using voting or weighted averages). Model-based algorithm: Bayes net or clustering. Hybrids incorporating domain knowledge or extra structure (e.g. demographics) work best. Evaluation: MAE or RMSE or ROC AUC.
2014-08-26	Article	http://www.deepminds.co/optimization.php	Multi-Armed Bandit Algorithms for Computational Advertising	Machine Learning	To-the-point comparison of bandit algorithms (epsilon-greedy, UCB1, MAB) with formulae for implementation.
2014-08-25	Video	https://www.youtube.com/watch?v=eAGEYhgpOgY	Deep Learning for NLP (without Magic) - Part 8	Machine Learning	Can model words as also having an operator function (interaction matrix with other words) in order to capture quantifiers like 'very' or 'not'. Increases performance on sentiment analysis task. Recursive deep learning is very good at inferring hierarchical structures. Can use Recursive neural networks for language modelling (better than n-gram models, especially with lower amounts of data). Can use strength of neural networks at learning hierarchical structures and increase performance of language model by predicting word categories given context and then words given categories (less expensive than straight words given context prediction). Lower perplexity, WER and BLEU (in machine translation)
2014-08-25	Video	https://www.youtube.com/watch?v=Wf156PweI70	Deep Learning for NLP (without Magic) - Part 7	Machine Learning	Can use same recursive neural network used for sentence parsing for image parsing (similar structural composition going on). Recursive auto-encoder gets state of the art performance on sentiment analysis without hand-crafted features. Doesn't even necessarily need a dictionary of positive and negative words. State of the art performance on paraphrase task because model is robust to syntactical changes.
2014-08-25	Video	https://www.youtube.com/watch?v=Wf156PweI70	Deep Learning for NLP (without Magic) - Part 6	Machine Learning	 Recursive neural networks can jointly learn word-vector representations and parse trees (syntax and semantics)- very strong to create semantic vector spaces of sentences.
2014-08-25	Video	https://www.youtube.com/watch?v=BS05lYioGkg	Deep Learning for NLP (without Magic) - Part 9	Machine Learning	Practical stuff for working with deep learning: libraries, tips from the trenches.
2014-08-25	Video	https://www.youtube.com/watch?v=5D_ZSpSZmSk	Deep Learning for NLP (without Magic) - Part 5	Machine Learning	Why does unsupervised pre-training work: places closer to better local optimum.
2014-08-25	Article	http://sebastianraschka.com/Articles/2014_intro_supervised_learning.html	Predictive modeling, supervised machine learning, and pattern classification - the big picture	Machine Learning	This article is the source of the excellent 'machine learning framework' flowchart. The article uses the diagram to explain all the basic machine learning concepts (data cleanup, visualization, feature engineering, model selection, error analysis).
2014-08-23	Article	http://www.bayesimpact.org/blog/walking-the-beat.html	Walking the Beat: Mining Seattle's Police Report Data	Data Science	Worked example of a data analytics task (outlier detection on police report data). Important first step when analyzing a data-set: understand the data collection mechanism (is it biased towards a particular type of event or time?). If dealing with categorical variables, try using domain knowledge to bin them and reduce dimensionality. Can use regression (e.g. GLM) to model if differences in occurrences of categorical values are correlated to something. Can use coefficient deviation (standard deviation normalized by mean) to see if groups are still comparable even though they have very different means.
2014-08-22	Video	https://www.youtube.com/watch?v=M3uWx-fhjUc	JavaScript Programming in the Large with Closure Tools	Libraries	Problems with JavaScript for large applications: no type checking, no namespaces, no access modifiers, difficult to modularize, managing dependencies. Unified set of tools to help: Closure (library, templates and compiler). Closure compiler can strip out unneeded parts of libraries so need to track minimal set of dependencies by hand. Removes whitespace, uglifies, rewrites/optimizes code to only have minimal code needed to cover all paths that are actually optimized. Can also eliminate platform-specific code. Also does type-checking using annotations.
2014-08-22	Paper	http://arxiv.org/pdf/1408.3218v1.pdf	Toward Automated Discovery of Artistic Influence	Computer Vision	Task: automatically finding all the influences on some painter. Unsupervised knowledge discovery task. Difficult. Solve correlated supervised task instead: style classification. Unsurprisingly, custom made high-level semantic features work better than generic low level features like SIFT.
2014-08-21	Video	https://www.youtube.com/watch?v=xPgLS3eAGO0	Deep Learning for NLP (without Magic) - Part 2	Machine Learning	How deep learning works expressed in NLP-maths terms. Every neuron essentially does no more than run a logistic regression. Feed them into each other recursively to get highly non-linear decision boundary - enables function approximation of very complicated functions. Deep networks need big non-linearities otherwise the deep nature won't offer benefits. Back-propagation (stochastic gradient descent) helps to make sure that lower layers learn good stuff. Unsupervised pre-training super important for performance of deep structures.
2014-08-21	Video	https://www.youtube.com/watch?v=_ahvzDzKdB0	Growing a Language	Computer Science	A talk on language design. Big languages are great but don't get done. Small languages take too much work to define productive units. Etc. The kicker: the talk only uses words of one syllable unless previously defined in order to make the point against small languages and for extensible languages.
2014-08-21	Video	https://www.youtube.com/watch?v=IF5tGEgRCTQ	Deep Learning for NLP (without Magic) - Part 1	Machine Learning	Most compelling reasons to use deep learning. Feature representation is learnt (reduced need for feature engineering over and over again for every domain/data-set). Ability to come up with distributional representations (less fragile than frequentist. Deals with curse of dimensionality) - network can learn kernel. Enables unsupervised and weight learning. Hierarchical feature representations: combinatorial sharing of statistic strength.
2014-08-21	Video	https://www.youtube.com/watch?v=6PmFSv5mg_E	Deep Learning for NLP (without Magic) - Part 3	Machine Learning	Using neural network to learn word vectors (for context). Take a word in context (positive example), replace word with unrelated word to generate negative example. Create vocabulary table. This gives representation of each word. Need to learn a function to combine these to phrases. Train neural net to discriminate between positive and negative phrases previously generated.
2014-08-21	Article	http://zeroturnaround.com/rebellabs/the-6-built-in-jdk-tools-the-average-developer-should-learn-to-use-more/	The 6 built-in JDK tools the average developer should learn to use more	Libraries	Overview of some of the tools that ship with a default Java JDK install. Most interesting: javap (disassembler), jjs (JavaScript console), jhat (heap analysis).
2014-08-20	Article	http://blog.faroo.com/2012/06/07/improved-edit-distance-based-spelling-correction/	1000x Faster Spelling Correction algorithm	Natural Language Processing	Spell checking: two main approaches. Naive way: edit distance between word and all other words in dictionary. Very expensive. Can make somewhat better by terminating edit distance computation when greater than some threshold. Peter Norvig way is faster: generate all words with edit distance less then some threshold and look them up in the dictionary. Problem: language dependent (more expensive for languages with large alphabet). Better: symmetric deleting approach. Pre-processing step: for every word in dictionary, also add all the words that can be created with at most N deletions. At lookup time, generate terms with an edit distance less than some threshold from input term and look them up in dictionary. Language independent and three orders of magnitude faster than Norvig way.
2014-08-19	Video	https://www.youtube.com/watch?v=csyL9EC0S0c	Programming is terrible - Lessons learned from a life wasted	Software Engineering	Entertaining rant on lots of things. Very good Q&A at the end. Main topics: code complexity, bad management targets, programming mono-culture, etc. ``Write code that is easy to replace, not easy to extend.'' Programming as a means to an end, not a skill in isolation.
2014-08-19	Video	https://www.youtube.com/watch?v=aWQUSiOZ0x8	The design sprint: from Google Ventures to Google[X]	Software Engineering	5-day design sprint: shorter than lean approach, less investment so easier to cut losses and throw a bad idea away. Tight deadline to get things done. Day 1: find 5 users in for user testing of idea at the end of the week, get right people for project on board. Day 2: find more than one idea, no group brainstorming but individual sketching full flows. Day 3: make good decisions using weighted voting (put stickers on parts of design people like) where core stakeholders have higher power. Day 4: battle royal between most voted ideas - mock all of them up and ready them for user testing. Day 5: run user study (data without launching). ``Learn early, learn often'' instead of ``ship early, ship often'' - ``rent before you buy.'' If there are different long-term and short-term stakeholders, use multiple design-sprint teams for different time-lines: requirements for 2 years from now or 4 years from now.
2014-08-19	Video	https://www.youtube.com/watch?v=XcT4yYu_TTs	How to Write Clean, Testable Code	Software Engineering	Tests should tell a story, project source should be re-constructable just from the tests. Writing tests (executable specs) before code leads to simpler implementation. Easy to test code splits construction of objects and wiring up from logic (if-statements) - easier to mock. Dev-environment should facilitate testing - need to invest in tooling to make writing and running tests easy. Three kings of bugs: thinking bugs (unit testing), wiring bugs (end-to-end tests), ``looks funny'' (humans). All relatively easy to fix. Super bugs appear when concerns are mixed.
2014-08-19	Video	https://www.youtube.com/watch?v=6O1gNVeaE4g	Fun is the Future: Mastering Gamification	Marketing	Fun and theme not correlated. Status most important motivator instead of cash. Reward early, reward often, don't go negative. Lower bar for engagement. As things become commodities, the customer loyalty becomes the goal.
2014-08-19	Video	https://www.youtube.com/watch?v=-C-JoyNuQJs	The JSON Saga	Software Engineering	JSON successful because it's at the intersection of different programming languages, not at the union: it allows to communicate things that every language has. No version number: stability over functionality.
2014-08-18	Video	https://www.youtube.com/watch?v=qCdpTji8nxo	How to Design Great APIs	Software Engineering	Intuitive: make similar things look similar, use parallel structure, dangerous things should be ugly. Great documentation: reference docs + tutorials + quick-start. Opinionated: pick one way and stick with it (coding conventions, stick to one underlying philosophy, etc.).
2014-08-18	Video	https://www.youtube.com/watch?v=heh4OeB9A-c	How To Design A Good API and Why it Matters	Software Engineering	Covers some of the same things as ``Effective Java''. New things include the following. API process. Start with 1-page spec, keep it agile and bounce the spec off other people and then implement towards this spec to test the API proposal (not a waste of time: can use as examples in documentation). Functionality should be easy to explain - if it's hard to name it probably does too much. ``When in doubt, leave it out.'' Easier to add things to an API than to remove. What to document: side-effects, who owns objects passed into methods, preconditions/postconditions. ``Don't make the client do anything the module could do.'' Principle of least astonishment.
2014-08-18	Video	https://www.youtube.com/watch?v=90NsjKvz9Ns	User Interface Algorithms	Computer Science	Voronoi tessellations to maximise hit-area for UI elements: a lot faster than computing closest points on mouse-move as only have to have a handler on Voronoi-cell enter and exit. Consider triangles to make menu dialog disappearing less annoying: the closer a user moves to a menu item, the more resistance there is to close the menu dialog. As long as the mouse moves more right than down, keep the menu open.
2014-08-18	Video	https://www.youtube.com/watch?v=012mt05yzjc	Best Practices in Javascript Library Design	Software Engineering	Using same methods and naming conventions on all objects. Fewer methods and less code is better: easier to learn, more maintainable. Generate test-case permutations. Structured format for documentation allows for custom documentation browsers - different people want to visualise documentation in different ways. Maintain library focus - opinionated. Lots of Javascript-specific stuff. Checking user-agent for quirks most reliable and easiest.
2014-08-18	Paper	http://arxiv.org/pdf/1404.3056.pdf	Principles of Antifragile Software	Software Engineering	Antifragility: getting better in the presence of errors. Examples: code that patches itself when encountering a bug. E.g. Netflix randomly crashes servers or increases/decreases latency to test their distributed algorithms. Need to minimize impact of errors e.g. via TDD + continuous deployment.
2014-08-17	Paper	http://www.win.tue.nl/~laroyo/2L340/resources/Amazon-Recommendations.pdf	Item-to-Item Collaborative Filtering	Machine Learning	Collaborative filtering finds similar users (e.g. using cosine similarity) and recommends items that one likes but not the other. Slow: O(M+N) where M is the number of users and N is the number of items. Can speed it up using dimensionality reduction but that hurts performance. Cluster-based recommendations split the user population into categories and generate local recommendations within the categories. Faster than collaborative filtering but still slow. Usually poor performance because clustering is not granular enough. Search-based recommendations use past interests as search queries to generate recommendations. Performs poorly for customers with large purchase histories due to difficulty of selecting the relevant items to based the query on. Item-to-item collaborative filtering finds similar items to the ones that a user likes and recommends those (e.g. by looking at items that are frequently purchased together - very sparse so easy to compute, can be computed off-line; on-line complexity is only related to user purchase history so essentially constant time).
2014-08-17	Paper	http://www.cs.umd.edu/~samir/498/10Algorithms-08.pdf	Top 10 algorithms in data mining	Machine Learning	Gentle overview of some basic machine learning algorithms. Some interesting observations. K-means: can fit non-spherical clusters by using more sophisticated distance metrics (e.g. KL divergence) or we can run k-means with large k and then use agglomerative clustering as a post-processing step (this technique also means that we don't have to select k and aren't sensitive to initial centroid choice). Apriori algorithm for frequent-item-set inference: iteratively grow and prune item-sets to avoid combinatorial explosion. Ada boost algorithm: iteratively fit a weak algorithm to a data-set and re-weight the data by the error of the learner (i.e. in the next round we'll learn a model that prioritizes the errors of the previous one), then get overall prediction using weighted average of all learners: ensemble learning technique outperforms performance of the individual learners. K-NN: it's possible to remove most of the data-points without harming accuracy. Naive Bayes: get a non-linear decision boundary by including interaction terms between attributes.
2014-08-17	Article	http://www.marketingdistillery.com/2014/08/10/multiple-abn-tests-in-marketing-with-anova-and-r/	Multiple A/B/n Tests in Marketing with ANOVA and R	Statistics	Multi-treatment A/B tests: ways to compute sample size and significance (ANOVA + Tukey Test). But why would we do something complicated like this if we could just use bandit algorithms?
2014-08-17	Article	http://www.bigdatanews.com/profiles/blogs/fast-clustering-algorithms-for-massive-datasets	Fast clustering algorithms for massive datasets	Machine Learning	O(n) clustering algorithm that iteratively reassigns items to clusters based on distances.
2014-08-16	Video	https://www.youtube.com/watch?v=bobeo5kFz1g	Bayesian statistics made (as) simple (as possible)	Statistics	Diachronic interpretation of Bayes' Theorem (belief update): P(H_{t+1}|E) = P(H_t) * P(E|H_t)/P(E).
2014-08-16	Video	https://www.youtube.com/watch?v=KaLROwp-VDY	How to get productive in a project in 24h	Software Engineering	Mining version control to find trouble spots in a code-base: periodic cycles of commits are bad. Using sonar or NDepend to measure types of cohesion and other types of smells: coupling-in and coupling-out, percentage of abstract over concrete coupling, etc. Important: evolution of code metrics over time (more important than point-values, especially if tied to check-ins to see commits or team-members who reduce/increase metrics over time). Beta-cohesion (how much of the object's state does the method touch) can help in deciding whether a method should go on an object or not. Cyclomatic complexity: how many branches in the code, good idea for refactoring. Code risk metrics: ratio of tests to cyclomatic complexity and how far test are away in the call graph.
2014-08-16	Video	https://www.youtube.com/watch?v=IWPgUn8tL8s	It's not what you read, it's what you ignore	Software Engineering	Effectiveness (doing the right things) vs efficiency (doing the thing right), single tasking.
2014-08-16	Video	https://www.youtube.com/watch?v=FPBVxpl8NMo	Why you should talk to strangers	Software Engineering	Taking inspiration from other languages and paradigms: higher order functions, contracts, actor-based.
2014-08-15	Video	https://www.youtube.com/watch?v=c-kav7Tf834	Maintainable JavaScript	Software Engineering	Importance of coding standards, programming principles and automation for readable and easily understandable code.
2014-08-15	Video	https://www.youtube.com/watch?v=_RRnyChxijA	Building a JavaScript-Based Game Engine for the Web	Libraries	Isometric JavaScript game engine (not canvas based).
2014-08-15	Video	https://www.youtube.com/watch?v=PV_cFx29Xz0	Javascript sucks and it doesn't matter	Libraries	Stuff to make development in JavaScript less painful: linters, unit testing libraries, testing of rendered pages using headless browsers like Zombie, avoid object orientation, amd for packaging.
2014-08-15	Paper	http://arxiv.org/pdf/1207.4169.pdf	The Author-Topic Model for Authors and Documents	Natural Language Processing	Augmenting LDA topic modelling with author information: opens up applications in stylometry and recommendations.
2014-08-15	Article	http://martiancraft.com/blog/2014/08/an-unreal-decision/	An Unreal Decision	Computer Graphics	Comparison of Unreal 4 engine and Unity.
2014-08-15	Article	http://fastml.com/calibrating-a-classifier-with-isotonic-regression/	Calibrating a classifier with isotonic regression	Machine Learning	Classifier calibration: some classifiers output probabilities that are biased (e.g. SVM and boosted trees are conservative) - need to calibrate classifiers if we need exact probabilities. Platt's scaling: fit SVM, predic class labels, fit logistic regression using the SVM predictions as features and the true labels as targets. The probability values from the logistic regression are the calibrated SVM probabilities.
2014-08-14	Video	https://www.youtube.com/watch?v=hjW4gL9hioY	How to Create Interactive Browser Visualizations from Python with Bokeh	Data Science	Bokeh library: like D3 but without having to use JavaScript.
2014-08-14	Video	https://www.youtube.com/watch?v=d1a4Jbjc-vU	The Future of Python - A Choose Your Own Adventure	Software Engineering	Interesting Python stuff: PyWeek (week-long game jam), Kivy (mobile apps library).
2014-08-13	Video	https://www.youtube.com/watch?v=xeAB10QgDW8	Machine learning the hard way -- a story about ponies	Machine Learning	Lessons: features with high variance can dominate other features, read the scikits-docs ;-) e.g. useful algorithm-choice cheat-sheet and hints on how to tune algorithms, can extend scikits with custom loss function, randomize training data.
2014-08-13	Paper	http://research.microsoft.com/en-us/um/people/nickcr/wscd2014/papers/wscdchallenge2014dataiku.pdf	Dataiku’s Solution to Yandex’s Personalized Web Search Challenge	Data Science	Winning a Kaggle learning-to-rank challenge. Interesting parts: using collaborative filtering for search re-ranking, quality of search snippet as a feature, trying to break the class-labels in the dataset up further. Hyper-parameter tuning was important.
2014-08-13	Book	http://www.amazon.co.uk/dp/B00HJUBRPG/	Don't Make Me Think, Revisited: A Common Sense Approach to Web Usability	Design	Short and a pleasure to read. Most of the topics covered shouldn't come as a surprise, but the book is a good way of bringing the most important web-design considerations back into active memory.
2014-08-13	Article	http://engineering.chartbeat.com/2014/08/13/you-dont-know-jack-about-hashing/	You Don’t Know Jack about Hashing	Computer Science	Beyond collisions for hash-function evaluation: avalanche property. Good avalanche characterisitcs: if we flip bit i in the original string there should be ~50% chance that we flip bit j in the hashed string for all i and j.
2014-08-12	Article	http://bbabenko.tumblr.com/post/83319141207/convolutional-learnings-things-i-learned-by	convolutional learnings: things i learned by implementing convolutional neural nets	Machine Learning	Practical issues when implementing neural networks: numerics, memory re-use, separate layers as much as possible (e.g. bias) for easier implementation, testing and re-use at the cost of speed.
2014-08-11	Paper	http://web.stanford.edu/~jpennin/papers/glove.pdf	GloVe: Global Vectors for Word Representation	Natural Language Processing	Semantic modelling: combine word-co-occurrence approach with word-context approach to get significantly better performance. Only consider non-zero elements of co-occurrence matrix in order to reduce noise. Not all training data is created equal: less in-domain data can outperform more out-of-domain data.
2014-08-11	Article	http://www.evanmiller.org/how-not-to-run-an-ab-test.html	How Not To Run An A/B Test	Machine Learning	Repeated significance error: stopping an A/B test early because of seeing significant results needs a lot higher actually observed significance in order not to risk getting bad result. Either commit to an experiment sample size or use approximate formulae to find the smallest possible sample size by relating minimum change to be detected and expected data variance. Or we could just avoid this problem altogether by using Bayesian methods that will give us a best estimate at any point in time.
2014-08-11	Article	http://www.chrisstucchio.com/blog/2013/time_varying_conversion_rates.html	How to measure a changing conversion rate (with python code)	Machine Learning	A/B tests, bandits, etc. assume that conversion rates are constant over time. Can relax this assumptions by using Jacobi diffusion instead (assume it's a random walk that approaches a constant).
2014-08-11	Article	http://www.chrisstucchio.com/blog/2013/bayesian_bandit.html	Bayesian Bandits - optimizing CTR with statistics	Machine Learning	Incorporating expert knowledge into the bandit algorithm via non-uniform priors.
2014-08-11	Article	http://www.chrisstucchio.com/blog/2012/bandit_algorithms_vs_ab.html	Why Multi-armed Bandit algorithms are superior to A/B testing	Machine Learning	UCB1 algorithm: introduce the use of confidence in bandit learning by estimating the best possible true mean of each arm and choosing the arm that maximizes this quantity.
2014-08-11	Article	http://tdunning.blogspot.com/2012/02/bayesian-bandits.html	Bayesian Bandits	Machine Learning	Mentions the concept of making exploration-time in bandit algorithms faster by factoring in the probability that each arm has of being the best so we don't waste time on arms that clearly have no chance of outperforming the others but still give some room to arms for which we merely don't have many observations: lack of evidence of success is not taken as evidence for failure.
2014-08-11	Article	http://streetpickup.hubpages.com/hub/Do-AB-Testing-the-right-way-Bayesian-bandits	Do A/B Testing the right way: Bayesian bandits	Machine Learning	Relates the Bayesian bandit to the Beta distribution, including probability update formula and shows the progression of likelihood of pull each arm over time.
2014-08-11	Article	http://stevehanov.ca/blog/index.php?id=132	20 lines of code that will beat A/B testing every time	Machine Learning	Simple description of bandit algorithms (epsilon-greedy learning) as applied to multiple-hypothesis A/B testing.
2014-08-11	Article	http://camdp.com/blogs/multi-armed-bandits	The Multi-Armed Bandit Problem	Machine Learning	How to measure bandit performance (expected regret) and extensions to the model: learning rates to adapt to changes in world faster, hierarchies of bandits in order to try out different parameters like learning rates.
2014-08-11	Article	http://camdp.com/blogs/machine-learning-counterexamples-pt2-post-pca-regr	ML Counterexamples Pt.2 - Regression Post-PCA	Machine Learning	Blindly dropping dimensions with low PCA-eigenvalues can harm performance if the lower-valued dimensions correlate highly with the attribute to be predicted. Supervised PCA fixes this.
2014-08-11	Article	http://camdp.com/blogs/machine-learning-counter-examples-pt1	Machine Learning Counterexamples Pt.1 - Discarding small coefficients in regression	Machine Learning	Small regression coefficients don't always imply low impact but can simply indicate correlated variables. Should validate before dropping features or just use a better model like ridge regression.
2014-08-10	Article	http://waldo.jaquith.org/blog/2011/02/ocr-video/	How I OCR Hundreds of Hours of Video	Libraries	API mashup to make videos searchable by extracting text-overlays from videos.
2014-08-10	Article	http://stevehanov.ca/blog/index.php?id=114	Fast and Easy Levenshtein distance using a Trie	Computer Science	Faster one-to-many edit distance algorithm.
2014-08-10	Article	http://snippyhollow.github.io/blog/2014/08/09/so-you-wanna-try-deep-learning/	So You Wanna Try Deep Learning?	Machine Learning	Practical intro to deep learning: libraries, papers, gotchas.
2014-08-09	Video	https://www.youtube.com/watch?v=fRN3nrrwngs	An introduction to video action recognition	Computer Vision	Media Lovin' Toolkit = good video processing library for Python. Action recognition = optical flow + Harris corner detection + clustering.
2014-08-09	Video	https://www.youtube.com/watch?v=bRzOBGLCRbc	Recommender Systems - The Art and Science of Matching Items to Users	Machine Learning	Unsupervised recommender systems. Baseline: cluster users + recommend most liked item in every cluster. Need to take exposure-to-item into consideration. Use random sub-population to get seeds in order to get rid of biases. Use bandit algorithm to find good seed items to suggest.
2014-08-09	Video	https://www.youtube.com/watch?v=GBzoNgqF-gQ	How to find patterns in large graphs	Computer Science	Graphs are not random. E.g. node-degree is Zipfian, can estimate number of three-way connections via eigenvalues. Can find similar laws for other quantities e.g. number of edges related to number of nodes over time, etc.
2014-08-09	Article	http://bertolami.com/index.php?engine=blog&content=posts&detail=perceptual-hashing	Perceptual Hashing	Computer Vision	SimHash for images.
2014-08-08	Article	http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html	Using scikit-learn Pipelines and FeatureUnions	Libraries	Sci-kit feature: pipeline to make working with feature extraction, transformation and model training easier.
2014-08-08	Article	http://www.technologyreview.com/view/529836/computational-linguistics-of-twitter-reveals-the-existence-of-global-superdialects/	Computational Linguistics of Twitter Reveals the Existence of Global Superdialects	Data Science	Putting the linguistics into computational linguistics. Analysis of tweets to find dialects... But actually followed up by interpretation using domain knowledge. Refreshing to see Twitter data used in a principled way.
2014-08-08	Article	http://www.datasciencecentral.com/profiles/blogs/17-analytic-disciplines-compared	16 analytic disciplines compared to data science	Data Science	Pretty in-depth comparison of different fields that are often confused or overlap with data science. Good reference for people asking about data science.
2014-08-08	Article	http://www.analyticsvidhya.com/blog/2014/08/visualizing-market-basket-analysis/	Visualizing product relationships in a market Basket analysis	Data Science	Graph-based discovery of related purchases.
2014-08-08	Article	http://radar.oreilly.com/2014/08/scaling-up-data-frames.html	Scaling up data frames	Data Science	How different environments implement data-frames: Spark, R, Python, Badger.
2014-08-07	Article	http://news.dice.com/2014/08/06/sourceforge-interview-new-game-engine/	SourceForge Interview: A New Game Engine	Libraries	Engine for card/board games.
2014-08-07	Article	http://firstround.com/article/How-design-thinking-transformed-Airbnb-from-failing-startup-to-billion-dollar-business	How Design Thinking Transformed Airbnb from a Failing Startup to a Billion Dollar Business	Management	Piece on the importance of dogfooding and just trying things out.
2014-08-07	Article	http://blogs.hbr.org/2014/08/the-question-to-ask-before-hiring-a-data-scientist/	The Question to Ask Before Hiring a Data Scientist	Data Science	Target audience of research influences requisite skills: machines or humans?
2014-08-07	Article	http://apassant.net/2014/05/09/sex-and-drugs-and-rocknroll-analysing-the-lyrics-of-the-rolling-stone-500-greatest-songs-of-all-time/	Sex and drugs and Rock’n’roll: Analysing the lyrics of the Rolling Stone 500 greatest songs of all time	Data Science	API mashup and some very, very basic NLP analysis (stemmed ngram frequencies).
2014-08-06	Video	https://www.youtube.com/watch?v=yg1ZVdpCbFs	Probabilistic Data Structures & Approximate Solutions	Computer Science	Randomized sampling. Bloom filter. Log-log/hash-based cardinality estimation. Count-min sketch. Approximate databases for faster queries e.g. BlinkDB.
2014-08-06	Video	https://www.youtube.com/watch?v=sAKTN-PeSwE	Committing to Recommendation Algorithms	Machine Learning	Using human validation in the recommender system loop.
2014-08-06	Video	https://www.youtube.com/watch?v=irP5RCdpilc	Algorithmic Illusions: Hidden Biases of Big Data	Data Science	Need to use different sources of data in order not to be blinded by sampling biases in data analysis.
2014-08-06	Video	https://www.youtube.com/watch?v=eLI6REKO7Qc	Getting it out there: Python, Javascript and Web-visualizations	Data Science	Pragmatic Python/Javascript for visualization.
2014-08-06	Video	https://www.youtube.com/watch?v=R_fZNQM-2o4	Measuring Similarity & Clustering Data	Machine Learning	K-means clustering: run multiple times to approach global optimum, does not work well if variance is uneven in different dimensions (assumes spherical data), works well in presence of redundant dimensions but breaks down with noise, distance in high dimensions is not meaningful, use silhouette score for evaluation (ratio of distance to cluster center to all other centroids). Spectral clustering: looks for close-by points that are not close to other points. Construct similarity graph of points, find graph Laplacian, eigenvalue decomposition, take smallest eigenvectors and run K-means in there => increases performance.
2014-08-06	Video	https://www.youtube.com/watch?v=LMHOilUtX8o	Storytelling in the Age of Big Data	Data Science	Using data for good - the need for a human story that motivates data analysis in order to bring about change.
2014-08-06	Video	https://www.youtube.com/watch?v=FX7qSwz3SCk	Introducing Dat: If Git Were Designed For Big Data	Computer Science	Databases/repositories for real-time data synchronization.
2014-08-06	Video	https://www.youtube.com/watch?v=A6qWCgGHT3k	Getting Big Benefits from Big Data	Data Science	Fluff. Need for communication of data science results to people who speak a different/business language.
2014-08-06	Article	https://medium.com/@JBramVB/mapping-happiness-with-twitter-natural-language-processing-ac231e70fe7	Mapping Happiness With Twitter Natural Language Processing	Data Science	Naively written-up API soup to perform and visualize sentiment analysis on Twitter.
2014-08-06	Article	http://unsupervisedlearning.wordpress.com/2014/08/04/topological-anomaly-detection/	Topological Anomaly Detection	Machine Learning	Interesting graph connectivity based anomaly detection approach.
2014-08-06	Article	http://mlwave.com/reflecting-back-on-one-year-of-kaggle-contests/	Reflecting back on one year of Kaggle contests	Data Science	Lots of great practical tricks to get the most out of machine learning techniques.
2014-08-05	Video	https://www.youtube.com/watch?v=zQFHHHwc-9g	Winning Ways for Your Visualization Plays	Data Science	Biases and pitfalls in visualization.
2014-08-05	Video	https://www.youtube.com/watch?v=t4IYPCnC5iA	Measuring and Predicting Departures from Routine in Human Mobility	Machine Learning	Using Bayesian Nets to model spatio-temporal behavior.
2014-08-05	Video	https://www.youtube.com/watch?v=jVMWT7I3ATM	Search is not a solved problem	Computer Science	Better search using real-time engagement metrics and content overlap.
2014-08-05	Video	https://www.youtube.com/watch?v=SpBeJxIiLSs	ApacheCon Keynote	Data Science	Motivational keynote: history, definition, current applications and future of data science.
2014-08-05	Video	https://www.youtube.com/watch?v=P74spbN4PLE	Real-World Machine Learning on Big Data: Which Methods Should You Use?	Machine Learning	Overview of different types of machine learning formulations and how to pragmatically choose between them: accuracy vs training/test speed vs interpretability vs simplicity.
2014-08-05	Video	https://www.youtube.com/watch?v=3Z8Y_NCS0Tk	Text mining to correct missing CRM information	Natural Language Processing	Tokenization + TF-IDF + SVD to find and propagate similarities in text.
2014-08-05	Book	http://www.amazon.co.uk/gp/product/B002RMSZ7E/	Apprenticeship Patterns: Guidance for the Aspiring Software Craftsman	Software Engineering	Very succinct and plainly written. Preaches nothing radically novel - if you've read The Pragmatic Programmer, The Mythical Man Month, Code Complete or other similar books you probably won't find many new ideas here. Being more to-the-point than any of the other tomes, the book would however make an excellent first foray into software craftsmanship.
2014-08-05	Article	https://scottlocklin.wordpress.com/2014/07/22/neglected-machine-learning-ideas/	Neglected machine learning ideas	Machine Learning	Pointers to common-in-the-real-world but less-well-covered-by-books machine learning topics: online learning, reinforcement learning, compression-based learning, time-series approaches, putting error bars on predictions, noisy data, feature engineering, unsupervised learning
2014-08-05	Article	http://wozniak.ca/what-orms-have-taught-me-just-learn-sql	What ORMs have taught me: just learn SQL	Computer Science	Problems with ORMs: too wide tables/too many attributes in class -> select * performance problems, links between classes -> foreign key join performance problems, information about object schema is replicated in database and code.
2014-08-05	Article	http://datascopeanalytics.com/what-we-think/2014/08/04/how-do-i-become-a-data-scientist-an-evaluation-of-3-alternatives	How do I become a data scientist? An evaluation of 3 alternatives	Data Science	Mostly fluff. Comparison of degree vs online courses vs bootcamp for data science education. Some good pointers to data science online courses and bootcamps.
2014-08-04	Video	https://www.youtube.com/watch?v=dBqyvpfHy8k	Authorship Attribution Using Python	Natural Language Processing	Stylometry using POS, word and character level TF-IDF 1,2,3-grams.
2014-08-04	Video	https://www.youtube.com/watch?v=Xg8UtTgziZE	Hierarchical Text Classification using Python (and friends)	Natural Language Processing	Interesting learning approach that uses tree-like structure in data explicitly.
2014-08-04	Video	https://www.youtube.com/watch?v=MdkHLS0FPMk	Most Winning A/B Test Results are Illusory	Statistics	Great list of A/B testing gotchas.
2014-08-04	Video	https://www.youtube.com/watch?v=CHjWMpWVaTQ	Recommenders in Python	Machine Learning	Basic recommender systems using distance measures and SVD.
2014-08-04	Book	http://columbia-applied-data-science.github.io/appdatasci.pdf	Applied Data Science	Data Science	Gentle introduction to basic data science concepts. The section on out-of-bag estimation for training of multiple classifiers on small amounts of data was interesting.
