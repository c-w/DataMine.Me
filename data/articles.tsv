Date	URL	Title	Topic	Summary
2014-08-05	https://scottlocklin.wordpress.com/2014/07/22/neglected-machine-learning-ideas/	Neglected machine learning ideas	Machine Learning	Pointers to common-in-the-real-world but less-well-covered-by-books machine learning topics: online learning, reinforcement learning, compression-based learning, time-series approaches, putting error bars on predictions, noisy data, feature engineering, unsupervised learning
2014-08-05	http://datascopeanalytics.com/what-we-think/2014/08/04/how-do-i-become-a-data-scientist-an-evaluation-of-3-alternatives	How do I become a data scientist? An evaluation of 3 alternatives	Data Science	Mostly fluff. Comparison of degree vs online courses vs bootcamp for data science education. Some good pointers to data science online courses and bootcamps.
2014-08-05	http://wozniak.ca/what-orms-have-taught-me-just-learn-sql	What ORMs have taught me: just learn SQL	Computer Science	Problems with ORMs: too wide tables/too many attributes in class -> select * performance problems, links between classes -> foreign key join performance problems, information about object schema is replicated in database and code.
2014-08-06	https://medium.com/@JBramVB/mapping-happiness-with-twitter-natural-language-processing-ac231e70fe7	Mapping Happiness With Twitter Natural Language Processing	Data Science	Naively written-up API soup to perform and visualize sentiment analysis on Twitter.
2014-08-06	http://mlwave.com/reflecting-back-on-one-year-of-kaggle-contests/	Reflecting back on one year of Kaggle contests	Data Science	Lots of great practical tricks to get the most out of machine learning techniques.
2014-08-06	http://unsupervisedlearning.wordpress.com/2014/08/04/topological-anomaly-detection/	Topological Anomaly Detection	Machine Learning	Interesting graph connectivity based anomaly detection approach.
2014-08-07	http://news.dice.com/2014/08/06/sourceforge-interview-new-game-engine/	SourceForge Interview: A New Game Engine	Libraries	Engine for card/board games.
2014-08-07	http://firstround.com/article/How-design-thinking-transformed-Airbnb-from-failing-startup-to-billion-dollar-business	How Design Thinking Transformed Airbnb from a Failing Startup to a Billion Dollar Business	Management	Piece on the importance of dogfooding and just trying things out.
2014-08-07	http://blogs.hbr.org/2014/08/the-question-to-ask-before-hiring-a-data-scientist/	The Question to Ask Before Hiring a Data Scientist	Data Science	Target audience of research influences requisite skills: machines or humans?
2014-08-07	http://apassant.net/2014/05/09/sex-and-drugs-and-rocknroll-analysing-the-lyrics-of-the-rolling-stone-500-greatest-songs-of-all-time/	Sex and drugs and Rock’n’roll: Analysing the lyrics of the Rolling Stone 500 greatest songs of all time	Data Science	API mashup and some very, very basic NLP analysis (stemmed ngram frequencies).
2014-08-08	http://www.technologyreview.com/view/529836/computational-linguistics-of-twitter-reveals-the-existence-of-global-superdialects/	Computational Linguistics of Twitter Reveals the Existence of Global Superdialects	Data Science	Putting the linguistics into computational linguistics. Analysis of tweets to find dialects... But actually followed up by interpretation using domain knowledge. Refreshing to see Twitter data used in a principled way.
2014-08-08	http://radar.oreilly.com/2014/08/scaling-up-data-frames.html	Scaling up data frames	Data Science	How different environments implement data-frames: Spark, R, Python, Badger.
2014-08-08	http://www.analyticsvidhya.com/blog/2014/08/visualizing-market-basket-analysis/	Visualizing product relationships in a market Basket analysis	Data Science	Graph-based discovery of related purchases.
2014-08-08	http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html	Using scikit-learn Pipelines and FeatureUnions	Libraries	Sci-kit feature: pipeline to make working with feature extraction, transformation and model training easier.
2014-08-08	http://www.datasciencecentral.com/profiles/blogs/17-analytic-disciplines-compared	16 analytic disciplines compared to data science	Data Science	Pretty in-depth comparison of different fields that are often confused or overlap with data science. Good reference for people asking about data science.
2014-08-09	http://bertolami.com/index.php?engine=blog&content=posts&detail=perceptual-hashing	Perceptual Hashing	Computer Vision	SimHash for images.
2014-08-10	http://stevehanov.ca/blog/index.php?id=114	Fast and Easy Levenshtein distance using a Trie	Computer Science	Faster one-to-many edit distance algorithm.
2014-08-10	http://snippyhollow.github.io/blog/2014/08/09/so-you-wanna-try-deep-learning/	So You Wanna Try Deep Learning?	Machine Learning	Practical intro to deep learning: libraries, papers, gotchas.
2014-08-10	http://waldo.jaquith.org/blog/2011/02/ocr-video/	How I OCR Hundreds of Hours of Video	Libraries	API mashup to make videos searchable by extracting text-overlays from videos.
2014-08-11	http://stevehanov.ca/blog/index.php?id=132	20 lines of code that will beat A/B testing every time	Machine Learning	Simple description of bandit algorithms (epsilon-greedy learning) as applied to multiple-hypothesis A/B testing.
2014-08-11	http://tdunning.blogspot.com/2012/02/bayesian-bandits.html	Bayesian Bandits	Machine Learning	Mentions the concept of making exploration-time in bandit algorithms faster by factoring in the probability that each arm has of being the best so we don't waste time on arms that clearly have no chance of outperforming the others but still give some room to arms for which we merely don't have many observations: lack of evidence of success is not taken as evidence for failure.
2014-08-11	http://streetpickup.hubpages.com/hub/Do-AB-Testing-the-right-way-Bayesian-bandits	Do A/B Testing the right way: Bayesian bandits	Machine Learning	Relates the Bayesian bandit to the Beta distribution, including probability update formula and shows the progression of likelihood of pull each arm over time.
2014-08-11	http://www.chrisstucchio.com/blog/2013/bayesian_bandit.html	Bayesian Bandits - optimizing CTR with statistics	Machine Learning	Incorporating expert knowledge into the bandit algorithm via non-uniform priors.
2014-08-11	http://camdp.com/blogs/multi-armed-bandits	The Multi-Armed Bandit Problem	Machine Learning	How to measure bandit performance (expected regret) and extensions to the model: learning rates to adapt to changes in world faster, hierarchies of bandits in order to try out different parameters like learning rates.
2014-08-11	http://www.chrisstucchio.com/blog/2012/bandit_algorithms_vs_ab.html	Why Multi-armed Bandit algorithms are superior to A/B testing	Machine Learning	UCB1 algorithm: introduce the use of confidence in bandit learning by estimating the best possible true mean of each arm and choosing the arm that maximizes this quantity.
2014-08-11	http://www.chrisstucchio.com/blog/2013/time_varying_conversion_rates.html	How to measure a changing conversion rate (with python code)	Machine Learning	A/B tests, bandits, etc. assume that conversion rates are constant over time. Can relax this assumptions by using Jacobi diffusion instead (assume it's a random walk that approaches a constant).
2014-08-11	http://www.evanmiller.org/how-not-to-run-an-ab-test.html	How Not To Run An A/B Test	Machine Learning	Repeated significance error: stopping an A/B test early because of seeing significant results needs a lot higher actually observed significance in order not to risk getting bad result. Either commit to an experiment sample size or use approximate formulae to find the smallest possible sample size by relating minimum change to be detected and expected data variance. Or we could just avoid this problem altogether by using Bayesian methods that will give us a best estimate at any point in time.
2014-08-11	http://camdp.com/blogs/machine-learning-counter-examples-pt1	Machine Learning Counterexamples Pt.1 - Discarding small coefficients in regression	Machine Learning	Small regression coefficients don't always imply low impact but can simply indicate correlated variables. Should validate before dropping features or just use a better model like ridge regression.
2014-08-11	http://camdp.com/blogs/machine-learning-counterexamples-pt2-post-pca-regr	ML Counterexamples Pt.2 - Regression Post-PCA	Machine Learning	Blindly dropping dimensions with low PCA-eigenvalues can harm performance if the lower-valued dimensions correlate highly with the attribute to be predicted. Supervised PCA fixes this.
2014-08-12	http://bbabenko.tumblr.com/post/83319141207/convolutional-learnings-things-i-learned-by	convolutional learnings: things i learned by implementing convolutional neural nets	Machine Learning	Practical issues when implementing neural networks: numerics, memory re-use, separate layers as much as possible (e.g. bias) for easier implementation, testing and re-use at the cost of speed.
2014-08-13	http://engineering.chartbeat.com/2014/08/13/you-dont-know-jack-about-hashing/	You Don’t Know Jack about Hashing	Computer Science	Beyond collisions for hash-function evaluation: avalanche property. Good avalanche characterisitcs: if we flip bit i in the original string there should be ~50% chance that we flip bit j in the hashed string for all i and j.
2014-08-15	http://martiancraft.com/blog/2014/08/an-unreal-decision/	An Unreal Decision	Computer Graphics	Comparison of Unreal 4 engine and Unity.
2014-08-15	http://fastml.com/calibrating-a-classifier-with-isotonic-regression/	Calibrating a classifier with isotonic regression	Machine Learning	Classifier calibration: some classifiers output probabilities that are biased (e.g. SVM and boosted trees are conservative) - need to calibrate classifiers if we need exact probabilities. Platt's scaling: fit SVM, predic class labels, fit logistic regression using the SVM predictions as features and the true labels as targets. The probability values from the logistic regression are the calibrated SVM probabilities.
2014-08-17	http://www.marketingdistillery.com/2014/08/10/multiple-abn-tests-in-marketing-with-anova-and-r/	Multiple A/B/n Tests in Marketing with ANOVA and R	Statistics	Multi-treatment A/B tests: ways to compute sample size and significance (ANOVA + Tukey Test). But why would we do something complicated like this if we could just use bandit algorithms?
2014-08-17	http://www.bigdatanews.com/profiles/blogs/fast-clustering-algorithms-for-massive-datasets	Fast clustering algorithms for massive datasets	Machine Learning	O(n) clustering algorithm that iteratively reassigns items to clusters based on distances.
2014-08-20	http://blog.faroo.com/2012/06/07/improved-edit-distance-based-spelling-correction/	1000x Faster Spelling Correction algorithm	Natural Language Processing	Spell checking: two main approaches. Naive way: edit distance between word and all other words in dictionary. Very expensive. Can make somewhat better by terminating edit distance computation when greater than some threshold. Peter Norvig way is faster: generate all words with edit distance less then some threshold and look them up in the dictionary. Problem: language dependent (more expensive for languages with large alphabet). Better: symmetric deleting approach. Pre-processing step: for every word in dictionary, also add all the words that can be created with at most N deletions. At lookup time, generate terms with an edit distance less than some threshold from input term and look them up in dictionary. Language independent and three orders of magnitude faster than Norvig way.
2014-08-21	http://zeroturnaround.com/rebellabs/the-6-built-in-jdk-tools-the-average-developer-should-learn-to-use-more/	The 6 built-in JDK tools the average developer should learn to use more	Libraries	Overview of some of the tools that ship with a default Java JDK install. Most interesting: javap (disassembler), jjs (JavaScript console), jhat (heap analysis).
2014-08-23	http://www.bayesimpact.org/blog/walking-the-beat.html	Walking the Beat: Mining Seattle's Police Report Data	Data Science	Worked example of a data analytics task (outlier detection on police report data). Important first step when analyzing a data-set: understand the data collection mechanism (is it biased towards a particular type of event or time?). If dealing with categorical variables, try using domain knowledge to bin them and reduce dimensionality. Can use regression (e.g. GLM) to model if differences in occurrences of categorical values are correlated to something. Can use coefficient deviation (standard deviation normalized by mean) to see if groups are still comparable even though they have very different means.
2014-08-25	http://sebastianraschka.com/Articles/2014_intro_supervised_learning.html	Predictive modeling, supervised machine learning, and pattern classification - the big picture	Machine Learning	This article is the source of the excellent 'machine learning framework' flowchart. The article uses the diagram to explain all the basic machine learning concepts (data cleanup, visualization, feature engineering, model selection, error analysis).
2014-08-26	http://www.deepminds.co/optimization.php	Multi-Armed Bandit Algorithms for Computational Advertising	Machine Learning	To-the-point comparison of bandit algorithms (epsilon-greedy, UCB1, MAB) with formulae for implementation.
2014-08-27	https://plus.google.com/+YoshuaBengio/posts/GJY53aahqS8	Response to: Is Deep Learning the Final Frontier and the End of Signal Processing?	Machine Learning	Why does deep learning work? Distributed representation: every extra layer can represent an exponentially bigger family of functions because parameters can be reused: N parameters can be used to split 2^N input regions. Much more effective than non-distributed non-parametric learners like SVM or KNN.
2014-08-28	http://jeremykun.com/2014/08/26/when-greedy-algorithms-are-perfect-the-matroid/	When Greedy Algorithms are Perfect: the Matroid	Computer Science	Matroid is a set of independence systems I over X such that any non-maximally independent set can be grown by adding an element from a bigger independent set. If a problem can be formulated as a Matroid then a greedy algorithm will always be optimal.
2014-08-28	http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/	Frequentism and Bayesianism: A Practical Introduction	Statistics	Frequentist approach treats probabilities as frequencies of events. Bayesian approach treats probabilities as notion of certainty of an event (prior knowledge + knowledge given observations). Advantage of Bayesian approach is that there is little need to change the model for more complicated problems (e.g. multi-dimensional or correlated data). Also doesn't make an implicit Gaussian assumption about the data or residuals. Drawback: overkill for simple problems.
2014-08-28	http://jakevdp.github.io/blog/2014/06/06/frequentism-and-bayesianism-2-when-results-differ/	Frequentism and Bayesianism II: When Results Differ	Statistics	Nuisance parameter: something that we have to estimate in order to measure the quantity we are interested in but that isn't directly relevant to the question at hand. Bayesian approach marginalizes them out, frequentist approach uses a single maximum likelihood estimate (which is probably going to be wrong - there are ways to fix this, but Bayesian formulation does it for free). Bayesian approach also better deals with outliers by accounting for them using a nuisance parameter and integrating their effect out.
2014-08-29	http://firstround.com/article/What-I-Learned-As-Pandoras-First-Data-Scientist	What I Learned As Pandora's First Data Scientist	Data Science	It's important to have data scientists situated with the product teams - shorter feedback loops, closer to the product, can pitch in on the actual implementation, etc. For a data scientist manager it's important to pair up people with projects that interest them and make sure that there is enough mentoring or peer-learning going on.
2014-09-29	http://blog.lostpropertyhq.com/postgres-full-text-search-is-good-enough/	Postgres full-text search is Good Enough!	Natural Language Processing	Lots of information retrieval functionality is built into Postgres by default: stemming, spell-checking, TF-IDF vectorization, query ranking, multi-language support, stop-wording, etc. This means we don't need to break out ElasticSearch for smaller scale full-text search.
2014-09-29	http://blog.notdot.net/2010/07/Damn-Cool-Algorithms-Levenshtein-Automata	Damn Cool Algorithms: Levenshtein Automata	Natural Language Processing	There is a way to construct finite state automata that compute the edit distance between two strings. This means that we can compute edit distance in linear time (plus some one-time overhead to construct the automata).
2014-11-25	http://blog.dominodatalab.com/using-data-science-to-get-a-good-deal-on-a-macbook	Using Data Science to get a Good Deal on a Macbook	Data Science	Some interesting pragmatic data pre-processing ideas. E.g.: using anomaly detection to remove the need for creating a labelled data set from a classification problem and using LDA to find regular expressions that will cheaply capture some aspects of clusters in the data.
2014-11-25	http://geoffboeing.com/2014/08/clustering-to-reduce-spatial-data-set-size	Clustering to Reduce Spatial Data Set Size	Machine Learning	Comparison of K-Means and DBSCAN clustering algorithms. Naturally the later wins because it is able to infer the number of clusters automatically and does not suffer from initialization problems.
2014-11-25	http://web.stanford.edu/~mwaskom/software/seaborn	Seaborn: statistical data visualization	Libraries	Wrapper around Matplotlib to make simple plot creation easier.
2014-11-25	http://fnl.es/a-review-of-sparse-sequence-taggers.html	A review of sparse sequence taggers	Libraries	Comparison of discriminative sequence tagging libraries based Conditional Random Fields (allows for any state in the sequence to be considered when making the tagging decision - prone to overfitting and slow) and MaxEnt Markov Models (only considers local context when making the tagging decision - fast and less likely to overfit but weaker features). Stanford Tagger, Mallet, CRF++ and SVM tool are too slow. OpenNLP only has MEMM, CRF Suite only has CRF. OpenNLP has no multi-core support. Wapiti is the best compromise between completeness, efficiency, documentation and accuracy.
2014-11-26	http://www.theverge.com/2014/11/25/7276157/nanogenmo-robot-author-novel	The strange world of computer-generated novels	Natural Language Processing	Very cool NLG idea: spend November (NaNoWriMo) writing a program to generate a novel.
2014-12-07	http://blog.david-andrzejewski.com/machine-learning/practical-machine-learning-tricks-from-the-kdd-2011-best-industry-paper	Practical machine learning tricks from the KDD 2011 best industry paper	Machine Learning	Some useful machine learning in the wild tricks from Google: use ensemble methods, get a human into the loop on low-confidence data-points, use many features and let L1 regularization trim the space down, avoid having to classify entries by ranking them instead (easier), monitor performance of system in the wild (e.g. permanently re-compute model precision and recall).
2015-01-18	http://engineering.shapesecurity.com/2015/01/detecting-phantomjs-based-visitors.html	Detecting Phantom JS-based visitors	Software Engineering	Interesting post talking about how to detect headless browsers. Most of the tips are fairly specific to Phantom JS, however, the post nicely shows the mindset to have if one truly wants to get rid of headless traffic: know and exploit the quirks in the headless rendering engines or use delay-based approaches.
2015-02-01	https://jmetzen.github.io/2015-01-29/ml_advice.html	Advice for applying Machine Learning	Data Science	Some interesting guidelines on how to get started tackling a new dataset. E.g., when data-dimensionality is low, use a correlation plot as a cheap way to separate noisy features from informative features and to filter out correlated features. E.g., plot learning curve to visualize difference in training versus cross-validation error. If training error is much higher than cross-validation error, we are likely over-fitting (fix by using more training data, stronger regularization or L1 regularization to force feature sparsity). If training error is very high, we are likely under-fitting i.e., using the wrong model for the data (fix by adding more features or non-linear kernels). E.g., use progressive validation when there is too much data for cross-validation: train model in batches, evaluate the model on the next batch, add the batch to the training data, re-evaluate and check how well we adapted to the new data - when we no longer improve, might as well stop training.
2015-02-04	http://scikit-learn.org/stable/tutorial/machine_learning_map/	Choosing the right estimator	Machine Learning	Awesome task-to-algorithm decision tree made by the Scikit-learn team. Gives a nice overview of which machine learning algorithms are canonical for what sorts of problems and requirements.
2015-02-04	http://svds.com/post/avoiding-common-mistake-time-series	Avoiding a common mistake with time series	Statistics	Cautionary tale about how trends in time series data can lead to strong correlations in unrelated data: if the trend is large compared to the actual data, the correlation between trends will overwhelm the non-correlation between the data. Work around: model the trend explicitly e.g. using linear regression and subtracting the fit or use differences between data points instead of raw data.
2015-02-13	http://www.firstclassanalytics.com/is-a-low-r-squared-statistic-a-bad-thing.html	Is A Low R-Squared Statistic A Bad Thing?	Statistics	The article argues that a low R^2 statistic for a regression model is not a bad thing for a model if the model attributes have good p-values -- low R^2 might simply mean that there are other attributes outside of our model that explain some of the variance in the data, not that the model we have is bad. We shouldn't indiscriminately add attributes to a model just to increase R^2 (as a matter of fact, the more attributes we add the higher R^2 is likely to be) but be judicious in choosing which attributes to add in adding more attributes (domain knowledge, p-values).
2015-02-13	http://www.kdnuggets.com/2015/02/10-things-statistics-big-data-analysis.html	10 things statistics taught us about big data analysis	Statistics	Some stats tricks relevant to machine learning. E.g. time-series data should be smoothed for better results. E.g. explicitly address confounding factors like inter-class variance over time.
2015-02-13	https://www.chrisstucchio.com/blog/2015/dont_use_bandits.html	Don't use Bandit Algorithms - they probably won't work for you	Statistics	Explanation of the underlying assumptions in some of the classic bandit algorithms and how frequent real-world experiment settings violate these (leading to worse performance than standard A/B tests). E.g. bandits assume no delay between impulse and response (real world conversion can take days). E.g. bandits assume uniform response rate (real world conversion and levers can be correlated).
2015-02-18	http://deloitte.wsj.com/cio/2015/02/10/why-data-storytelling-is-so-important-and-why-were-so-bad-at-it/	Why Data Storytelling is So Important, and Why We're So Bad at It	Data Science	Mostly fluff/obvious piece about why adding a story to data analysis is important (more easily understood by stakeholders, etc.), but with one interesting point. Given that there are supposedly only 7 types of literary narratives, using stories to communicate the results of data analytics might enable us to standardize the stories we tell with the analytics to a similar set of standard pieces. This will make it easier to communicate the high level picture of the analysis.
2015-02-18	https://hbr.org/2014/05/10-kinds-of-stories-to-tell-with-data/	10 Kinds of Stories to Tell with Data	Data Science	Taxonomy of different types of analytics stories along dimensions. Time: reporting (describing the past), surveying (explaining the present), predicting (modelling the future). Focus: what is going on, why is it going on, how to fix it. Methods: correlation story, causation story (requires experiment).
2015-03-04	http://hunch.net/?p=22	Clever Methods of Overfitting	Machine Learning	Good enumeration of different ways in which we can over-fit models, ranging from the classic 'too complex model with too little data' over to 'too finely tuned meta-parameters' to more subtle points like choosing the metric that makes our algorithm look good or choosing metrics that are inherently prone to over-fitting (like entropy, mutual information or leave-one-out cross validation).
2015-03-21	http://technology.stitchfix.com/blog/2015/03/17/grammar-of-data-science	The Grammar of Data Science	Data Visualization	The article compares using R over Python for exploratory data analysis and gives some compelling arguments in favour of R. Most interestingly, R is able to plot categorical versus numeric data out of the box!
2015-03-21	http://www.kdnuggets.com/2015/03/machine-learning-data-science-common-mistakes.html	7 common mistakes when doing Machine Learning	Machine learning	Don't always use the default loss function (e.g. Huber loss is good to not heavily penalize outliers and hinge loss is good to not penalize small mistakes). Add interaction terms to achieve non-linearity when using linear models, e.g. logistic regression. Always check for outliers! Always standardize features when using regularization. Coefficient sizes of linear models not always interpretable as feature importance, e.g. when attributes co-linear or not standardized.
2015-03-21	http://engineering.intenthq.com/2015/02/automatic-topic-modelling-with-lda	Automatic topic-modelling with Latent Dirichlet Allocation	Natural Language Processing	Useful comparison of a bunch of different LDA libraries, e.g. MALLET is no longer being developed and we should probably all be using GenSim due to focus on performance and ease-of-use.
2015-03-21	http://www.win-vector.com/blog/2015/02/does-balancing-classes-improve-classifier-performance	Machine Learning	Does Balancing Classes Improve Classifier Performance?	The article experimentally explores how over-sampling a minority class affects classification performance of logistic regression, random forest and soft-margin support vector machine. Turns out that over-sampling is a really bad idea for logistic regression (logistic regression calibrates well to the distribution of the data so fudging the distribution will naturally affect performance), does not affect support vector machine (the training procedure is not strongly dependent on class distribution: performance depends on class distance from the margin - if both classes are far away from the margin, their distribution doesn't matter much) and improves performance of random forest. On the bright side: over-sampling will necessarily increase recall.
2015-03-21	http://blog.echen.me/2014/10/07/moving-beyond-ctr-better-recommendations-through-human-evaluation	Moving Beyond CTR: Better Recommendations Through Human Evaluation	Machine Learning	Interesting essay on trying to move away from click-through-rate as the main way of evaluating the performance of recommender systems. The article argues that click-through-rate is expensive to experiment with (requires full-scale A/B test) and is a poor proxy for quality of recommendations (clicks do not necessarily imply satisfaction with the content). The article argues that we should be using human evaluation to validate new recommenders (which also allows us to get feedback while building a new algorithm, not only once we're done and productionized). Obviously, there are some issues with the approach recommended by the article: it is hard to scale human evaluation and there is no jeopardy for the participant, i.e. although they might say that they are satisfied with some recommendation, that does not necessarily translate into purchase intent given that agreeing with some recommendation does not cost the participant anything. Using human evaluation during the prototyping phase of recommender development, on the other hand, does sound appealing.
